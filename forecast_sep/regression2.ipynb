{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7a7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['cme_count_lag1', 'cme_count_lag2', 'cme_count_lag3', 'cme_count_rollsum3', 'cme_count_rollmax3', 'halo_count_lag1', 'halo_count_lag2', 'halo_count_lag3', 'halo_count_rollsum3', 'halo_count_rollmax3', 'partial_halo_count_lag1', 'partial_halo_count_lag2', 'partial_halo_count_lag3', 'partial_halo_count_rollsum3', 'partial_halo_count_rollmax3', 'width_max_lag1', 'width_max_lag2', 'width_max_lag3', 'width_max_rollsum3', 'width_max_rollmax3', 'width_mean_lag1', 'width_mean_lag2', 'width_mean_lag3', 'width_mean_rollsum3', 'width_mean_rollmax3', 'speed_linear_max_lag1', 'speed_linear_max_lag2', 'speed_linear_max_lag3', 'speed_linear_max_rollsum3', 'speed_linear_max_rollmax3', 'speed_linear_mean_lag1', 'speed_linear_mean_lag2', 'speed_linear_mean_lag3', 'speed_linear_mean_rollsum3', 'speed_linear_mean_rollmax3', 'speed_init_max_lag1', 'speed_init_max_lag2', 'speed_init_max_lag3', 'speed_init_max_rollsum3', 'speed_init_max_rollmax3', 'speed_final_max_lag1', 'speed_final_max_lag2', 'speed_final_max_lag3', 'speed_final_max_rollsum3', 'speed_final_max_rollmax3', 'speed_20R_max_lag1', 'speed_20R_max_lag2', 'speed_20R_max_lag3', 'speed_20R_max_rollsum3', 'speed_20R_max_rollmax3', 'accel_max_lag1', 'accel_max_lag2', 'accel_max_lag3', 'accel_max_rollsum3', 'accel_max_rollmax3', 'accel_min_lag1', 'accel_min_lag2', 'accel_min_lag3', 'accel_min_rollsum3', 'accel_min_rollmax3', 'mass_sum_lag1', 'mass_sum_lag2', 'mass_sum_lag3', 'mass_sum_rollsum3', 'mass_sum_rollmax3', 'mass_max_lag1', 'mass_max_lag2', 'mass_max_lag3', 'mass_max_rollsum3', 'mass_max_rollmax3', 'ke_sum_lag1', 'ke_sum_lag2', 'ke_sum_lag3', 'ke_sum_rollsum3', 'ke_sum_rollmax3', 'ke_max_lag1', 'ke_max_lag2', 'ke_max_lag3', 'ke_max_rollsum3', 'ke_max_rollmax3']\n",
      "Metrics: {'rmse': np.float64(0.15687698284726329), 'r2': -7.109058573666582}\n",
      "Dataset length: 361\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) CME 전처리: 월별 txt 모두 로드 -> Halo만 -> 일별 합/횟수 -> 누락일 0 채움\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def load_and_preprocess_cme_multifeature(year: int, cme_dir: str):\n",
    "\n",
    "    cme_dir = Path(cme_dir)\n",
    "    files = [cme_dir / f\"univ{year}_{m:02d}.txt\" for m in range(1, 13)]\n",
    "\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        if not f.exists():\n",
    "            continue\n",
    "\n",
    "        # fixed width\n",
    "        df = pd.read_fwf(\n",
    "            f,\n",
    "            skiprows=4,\n",
    "            header=None\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    cme = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 컬럼 구조 (실제 카탈로그 기준)\n",
    "    # -----------------------------------\n",
    "    # 0 : Date\n",
    "    # 1 : Time\n",
    "    # 2 : Central PA   (or Halo)\n",
    "    # 3 : Width\n",
    "    # 4 : Linear speed\n",
    "    # 5 : 2nd order speed (initial)\n",
    "    # 6 : 2nd order speed (final)\n",
    "    # 7 : 2nd order speed (20R)\n",
    "    # 8 : Accel\n",
    "    # 9 : Mass\n",
    "    # 10: Kinetic energy\n",
    "    # 11: MPA\n",
    "    # 12: Remarks\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "\n",
    "    out[\"date\"] = pd.to_datetime(cme.iloc[:, 0], errors=\"coerce\")\n",
    "\n",
    "    # halo / partial halo flag\n",
    "    central = cme.iloc[:, 2].astype(str)\n",
    "    out[\"is_halo\"] = central.str.contains(\"Halo\", case=False, na=False).astype(int)\n",
    "    out[\"is_partial_halo\"] = cme.iloc[:, 12].astype(str).str.contains(\n",
    "        \"Partial\", case=False, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "    # numeric columns\n",
    "    def num(col):\n",
    "        return pd.to_numeric(\n",
    "            cme.iloc[:, col].astype(str).str.replace(\"*\", \"\", regex=False),\n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "\n",
    "    out[\"width\"] = num(3)\n",
    "    out[\"speed_linear\"] = num(4)\n",
    "    out[\"speed_init\"] = num(5)\n",
    "    out[\"speed_final\"] = num(6)\n",
    "    out[\"speed_20R\"] = num(7)\n",
    "    out[\"accel\"] = num(8)\n",
    "\n",
    "    # mass, energy는 ------- 같은 값이 있으므로 그대로 numeric 처리\n",
    "    out[\"mass\"] = num(9)\n",
    "    out[\"kinetic_energy\"] = num(10)\n",
    "\n",
    "    out = out.dropna(subset=[\"date\"])\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 하루 단위 aggregation\n",
    "    # -----------------------------------\n",
    "    daily = (\n",
    "        out\n",
    "        .groupby(\"date\")\n",
    "        .agg(\n",
    "            cme_count = (\"date\", \"count\"),\n",
    "\n",
    "            halo_count = (\"is_halo\", \"sum\"),\n",
    "            partial_halo_count = (\"is_partial_halo\", \"sum\"),\n",
    "\n",
    "            width_max = (\"width\", \"max\"),\n",
    "            width_mean = (\"width\", \"mean\"),\n",
    "\n",
    "            speed_linear_max = (\"speed_linear\", \"max\"),\n",
    "            speed_linear_mean = (\"speed_linear\", \"mean\"),\n",
    "\n",
    "            speed_init_max = (\"speed_init\", \"max\"),\n",
    "            speed_final_max = (\"speed_final\", \"max\"),\n",
    "            speed_20R_max = (\"speed_20R\", \"max\"),\n",
    "\n",
    "            accel_max = (\"accel\", \"max\"),\n",
    "            accel_min = (\"accel\", \"min\"),\n",
    "\n",
    "            mass_sum = (\"mass\", \"sum\"),\n",
    "            mass_max = (\"mass\", \"max\"),\n",
    "\n",
    "            ke_sum = (\"kinetic_energy\", \"sum\"),\n",
    "            ke_max = (\"kinetic_energy\", \"max\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # -----------------------------------\n",
    "    # 날짜 채우기\n",
    "    # -----------------------------------\n",
    "    full_dates = pd.date_range(\n",
    "        pd.Timestamp(year, 1, 1),\n",
    "        pd.Timestamp(year, 12, 31),\n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    daily = (\n",
    "        daily\n",
    "        .set_index(\"date\")\n",
    "        .reindex(full_dates)\n",
    "        .rename_axis(\"date\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # count 계열은 0, 나머지는 0으로 채워줌(모델용)\n",
    "    count_cols = [\n",
    "        \"cme_count\", \"halo_count\", \"partial_halo_count\"\n",
    "    ]\n",
    "    for c in count_cols:\n",
    "        daily[c] = daily[c].fillna(0)\n",
    "\n",
    "    other_cols = [c for c in daily.columns if c not in [\"date\"] + count_cols]\n",
    "    daily[other_cols] = daily[other_cols].fillna(0)\n",
    "\n",
    "    return daily\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) hproton 전처리: 메타라인 섞여도 안전하게 -> date 만들기 -> p_gt_100만\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_hproton(dpd_path: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with open(dpd_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            parts = line.split()\n",
    "            if len(parts) < 6:   # 최소 year month day p1 p10 p100 있어야 함\n",
    "                continue\n",
    "\n",
    "            # 첫 3개가 정수여야 데이터 줄로 인정\n",
    "            try:\n",
    "                y = int(float(parts[0]))\n",
    "                m = int(float(parts[1]))\n",
    "                d = int(float(parts[2]))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            # 데이터 줄이면 앞 9개까지 안전하게 읽기 (없으면 NaN 채움)\n",
    "            vals = parts[:9] + [np.nan] * (9 - len(parts[:9]))\n",
    "            rows.append([y, m, d] + vals[3:9])\n",
    "\n",
    "    hp = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\n",
    "            \"year\", \"month\", \"day\",\n",
    "            \"p_gt_1MeV\", \"p_gt_10MeV\", \"p_gt_100MeV\",\n",
    "            \"e_gt_0p6MeV\", \"e_gt_2MeV\",\n",
    "            \"neutron_pct\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 숫자 변환\n",
    "    for c in [\"p_gt_1MeV\",\"p_gt_10MeV\",\"p_gt_100MeV\",\"e_gt_0p6MeV\",\"e_gt_2MeV\",\"neutron_pct\"]:\n",
    "        hp[c] = pd.to_numeric(hp[c], errors=\"coerce\")\n",
    "\n",
    "    hp[\"date\"] = pd.to_datetime(hp[[\"year\",\"month\",\"day\"]])\n",
    "    hp = hp[[\"date\", \"p_gt_100MeV\"]].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # 결측은 0으로(원하면 그대로 NaN 둬도 됨)\n",
    "    hp[\"p_gt_100MeV\"] = hp[\"p_gt_100MeV\"].fillna(0.0)\n",
    "\n",
    "    return hp\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) CME + hproton 길이 n 맞추기(동일 date index로 reindex)\n",
    "# -----------------------------\n",
    "def align_daily_series(cme_daily: pd.DataFrame, hp_daily: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 공통 날짜 범위(교집합)로 맞추고 싶으면 여기서 start/end 조절 가능\n",
    "    start = max(cme_daily[\"date\"].min(), hp_daily[\"date\"].min())\n",
    "    end   = min(cme_daily[\"date\"].max(), hp_daily[\"date\"].max())\n",
    "    full_dates = pd.date_range(start, end, freq=\"D\")\n",
    "\n",
    "    cme_aligned = (\n",
    "        cme_daily.set_index(\"date\")\n",
    "        .reindex(full_dates, fill_value=0)\n",
    "        .rename_axis(\"date\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    hp_aligned = (\n",
    "        hp_daily.set_index(\"date\")\n",
    "        .reindex(full_dates, fill_value=0)\n",
    "        .rename_axis(\"date\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    merged = pd.merge(cme_aligned, hp_aligned, on=\"date\", how=\"inner\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) (과거 k일 CME) -> (오늘 SEP) 학습용 테이블 생성\n",
    "# -----------------------------\n",
    "def make_supervised_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    base_feature_cols=None,\n",
    "    k_lag: int = 3,\n",
    "    future_window: int = 3,\n",
    "    use_log_target: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    df: must include columns ['date', 'p_gt_100MeV'] + CME feature columns\n",
    "\n",
    "    base_feature_cols: CME feature columns list.\n",
    "      - None이면 자동으로 (date, p_gt_100MeV) 제외한 모든 컬럼을 feature로 사용.\n",
    "    \"\"\"\n",
    "\n",
    "    out = df.sort_values(\"date\").reset_index(drop=True).copy()\n",
    "\n",
    "    # ✅ feature 컬럼 자동 선택\n",
    "    if base_feature_cols is None:\n",
    "        base_feature_cols = [c for c in out.columns if c not in [\"date\", \"p_gt_100MeV\"]]\n",
    "\n",
    "    # ------------------------\n",
    "    # 1) lag / rolling features\n",
    "    # ------------------------\n",
    "    feat_cols = []\n",
    "    for col in base_feature_cols:\n",
    "        # lag\n",
    "        for lag in range(1, k_lag + 1):\n",
    "            name = f\"{col}_lag{lag}\"\n",
    "            out[name] = out[col].shift(lag)\n",
    "            feat_cols.append(name)\n",
    "\n",
    "        # rolling sum (최근 k일 합)\n",
    "        name = f\"{col}_rollsum{k_lag}\"\n",
    "        out[name] = out[col].shift(1).rolling(k_lag).sum()\n",
    "        feat_cols.append(name)\n",
    "\n",
    "        # rolling max (최근 k일 최대)\n",
    "        name = f\"{col}_rollmax{k_lag}\"\n",
    "        out[name] = out[col].shift(1).rolling(k_lag).max()\n",
    "        feat_cols.append(name)\n",
    "\n",
    "    # ------------------------\n",
    "    # 2) target: 미래 window max SEP\n",
    "    # ------------------------\n",
    "    out[\"target_sep\"] = (\n",
    "        out[\"p_gt_100MeV\"]\n",
    "        .shift(-1)\n",
    "        .rolling(future_window)\n",
    "        .max()\n",
    "    )\n",
    "\n",
    "    # ------------------------\n",
    "    # 3) dropna and return\n",
    "    # ------------------------\n",
    "    model_df = out[[\"date\"] + feat_cols + [\"target_sep\"]].dropna().reset_index(drop=True)\n",
    "\n",
    "    X = model_df[feat_cols].values\n",
    "    y = model_df[\"target_sep\"].values\n",
    "\n",
    "    if use_log_target:\n",
    "        y = np.log10(y + 1.0)\n",
    "\n",
    "    return model_df, feat_cols, X, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) 모델 학습/평가 (시간 순서 유지)\n",
    "# -----------------------------\n",
    "def train_and_evaluate(X, y):\n",
    "    # 가장 단순한 baseline: RandomForestRegressor\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 마지막 20%를 테스트로 (time split)\n",
    "    n = len(X)\n",
    "    split = int(n * 0.8)\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "\n",
    "    return model, {\"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 실행 예시\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    year = 2002\n",
    "    cme_dir = f\"./{year}cme\"          # 너 폴더 구조에 맞게\n",
    "    dpd_path = f\"./{year}_DPD.txt\"    # 너 파일명에 맞게\n",
    "\n",
    "    k_lag = 3  # 과거 3일 CME로 오늘 SEP 예측\n",
    "\n",
    "    cme_daily = load_and_preprocess_cme_multifeature(year, cme_dir)\n",
    "    hp_daily  = load_and_preprocess_hproton(dpd_path)\n",
    "\n",
    "    merged = align_daily_series(cme_daily, hp_daily)\n",
    "\n",
    "    ds, feature_cols, X, y = make_supervised_dataset(\n",
    "        merged,\n",
    "        k_lag=3,\n",
    "        future_window=3,\n",
    "        use_log_target=True\n",
    "    )\n",
    "\n",
    "\n",
    "    model, metrics = train_and_evaluate(X, y)\n",
    "\n",
    "    print(\"Features:\", feature_cols)\n",
    "    print(\"Metrics:\", metrics)\n",
    "    print(\"Dataset length:\", len(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9660259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event days: 361 / 361\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"event days:\",\n",
    "    (ds[\"target_sep\"] > 0).sum(),\n",
    "    \"/\",\n",
    "    len(ds)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1202fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
